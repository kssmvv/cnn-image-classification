{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805fb6d2",
   "metadata": {},
   "source": [
    "# Transfer Learning on Oxford Flowers 102\n",
    "\n",
    "This notebook demonstrates how to fine-tune a pretrained **MobileNetV2** (ImageNet) on the **Oxford Flowers 102** dataset using PyTorch. We also compare different data augmentation strategies and their effect on accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc92089",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Flowers102\n",
    "\n",
    "train_data_raw = Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"train\",\n",
    "    transform=None,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_data_raw = Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"val\",\n",
    "    transform=None,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data_raw = Flowers102(\n",
    "    root=\"data\",\n",
    "    split=\"test\",\n",
    "    transform=None,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_data_raw)}\")\n",
    "print(f\"Val size: {len(val_data_raw)}\")\n",
    "print(f\"Test size: {len(test_data_raw)}\")\n",
    "print(f\"\\nNumber of classes: {len(set(train_data_raw._labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_image():\n",
    "    idx = random.randint(0, len(train_data_raw) - 1)\n",
    "    img, label = train_data_raw[idx]\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'Class {label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0426c4f1",
   "metadata": {},
   "source": [
    "## Data Transforms and Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeec391",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd35586",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Flowers102(root=\"data\", split=\"train\", transform=train_transform, download=True)\n",
    "val_data = Flowers102(root=\"data\", split=\"val\", transform=val_test_transform, download=True)\n",
    "test_data = Flowers102(root=\"data\", split=\"test\", transform=val_test_transform, download=True)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}, Test batches: {len(test_loader)}\")\n",
    "\n",
    "imgs, lbls = next(iter(train_loader))\n",
    "print(f\"Batch: {imgs.shape}, Labels: {lbls.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210f87f",
   "metadata": {},
   "source": [
    "## Pretrained MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e309b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 102\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "print(model.classifier)\n",
    "\n",
    "\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total params: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce53f3b",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for imgs, labels in loader:\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f80298",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val = 0.0\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_acc = get_accuracy(model, val_loader)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "\n",
    "    \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} | Loss: {train_loss:.4f} | Train: {train_acc:.4f} | Val: {val_acc:.4f} | LR: {lr:.6f}\")\n",
    "\n",
    "print(f\"Best val accuracy: {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab87ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(train_losses)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(train_accs, label='Train')\n",
    "ax2.plot(val_accs, label='Val')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11cdce5",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = get_accuracy(model, test_loader)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469b74b",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct = []\n",
    "incorrect = []\n",
    "\n",
    "indices = list(range(len(test_data)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "for idx in indices:\n",
    "    if len(correct) >= 5 and len(incorrect) >= 5:\n",
    "        break\n",
    "        \n",
    "    img, label = test_data_raw[idx]\n",
    "    img_t, _ = test_data[idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(img_t.unsqueeze(0)).argmax(1).item()\n",
    "    \n",
    "    if pred == label and len(correct) < 5:\n",
    "        correct.append((img, label, pred))\n",
    "    elif pred != label and len(incorrect) < 5:\n",
    "        incorrect.append((img, label, pred))\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, (img, label, pred) in enumerate(correct):\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f'{label} | {pred}', color='green')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "for i, (img, label, pred) in enumerate(incorrect):\n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].set_title(f'{label} | {pred}', color='red')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d6176",
   "metadata": {},
   "source": [
    "## Augmentation Experiments\n",
    "\n",
    "Let's compare the baseline augmentation pipeline against a more aggressive one that adds vertical flips, random rotation, and stronger Gaussian blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e75f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 3.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "train_data_adv = Flowers102(root=\"data\", split=\"train\", transform=advanced_transform, download=True)\n",
    "train_loader_adv = DataLoader(train_data_adv, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "model_aug.classifier[1] = nn.Linear(model_aug.classifier[1].in_features, 102)\n",
    "\n",
    "criterion_aug = nn.CrossEntropyLoss()\n",
    "optimizer_aug = optim.Adam(model_aug.parameters(), lr=1e-3)\n",
    "scheduler_aug = optim.lr_scheduler.StepLR(optimizer_aug, step_size=30, gamma=0.1)\n",
    "\n",
    "num_epochs_adv = 5\n",
    "train_losses_adv = []\n",
    "train_accs_adv = []\n",
    "val_accs_adv = []\n",
    "\n",
    "for epoch in range(1, num_epochs_adv + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model_aug, train_loader_adv, criterion_aug, optimizer_aug)\n",
    "    val_acc = get_accuracy(model_aug, val_loader)\n",
    "\n",
    "    scheduler_aug.step()\n",
    "\n",
    "    train_losses_adv.append(train_loss)\n",
    "    train_accs_adv.append(train_acc)\n",
    "    val_accs_adv.append(val_acc)\n",
    "\n",
    "    lr = optimizer_aug.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} | Loss: {train_loss:.4f} | Train: {train_acc:.4f} | Val: {val_acc:.4f} | LR: {lr:.6f}\")\n",
    "\n",
    "test_acc_aug = get_accuracy(model_aug, test_loader)\n",
    "print(f\"\\nAdvanced augmentation test accuracy: {test_acc_aug:.4f}\")\n",
    "print(f\"Original test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Difference: {test_acc_aug - test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de84fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(train_losses, label='Original')\n",
    "ax1.plot(train_losses_adv, label='Advanced Aug')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(val_accs, label='Original')\n",
    "ax2.plot(val_accs_adv, label='Advanced Aug')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Validation Accuracy Comparison')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
